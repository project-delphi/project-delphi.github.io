<!--
.. title: Mixed Effects (aka Hierarchical Models) vs Resampling?
.. slug: mixed-effects-aka-hierarchical-models-vs-resampling
.. date: 2019-10-08 21:37:33 UTC-04:00
.. tags: 
.. category: 
.. link: 
.. description: 
.. type: text
-->

Investigating fixed effects, random effects, mixed effects I felt queasy having to remember all these terms. It reminded me of [lasso & ridge regression or L1 & L2](https://stats.stackexchange.com/questions/200416/is-regression-with-l1-regularization-the-same-as-lasso-and-with-l2-regularizati) - naming concepts in statistics often feel unnecessarily complicated compared to computer science. 

This [post](https://statmodeling.stat.columbia.edu/2005/01/25/why_i_dont_use/) from Andrew Gelman made me think of mirror universes from the Star Trek Genre.

![](https://wwwimage-secure.cbsstatic.com/base/files/cea5c227c75c9531_dsc_mirror_georgious.jpg)

It's just so much nicer to think of all these effects as just being generated by hierarchical models with different hyperparameters on the priors. Having to remember the whole sequence of `* effects` models can be exhausting before even getting to the analysis.

His point holds, many frequentist family models are just one or other way of saying things that might naturally be framed as Bayesian problems. This resonates particularly well with mixed effects and hierarhical modelling.

![](https://i.imgflip.com/3craxc.jpg)

What has me interested, is if it's possible to model the fixed and random effects, or hierarhical model of feature weights through re-sampling strategies. I've never seen that done before.

This would open up a third mirror universe where resampling strategies could be used to approximate mixed effects/hierarchical models.

![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQt1y4TKw9m_ojbyAIdC1UfuNfBvBknU9GvbKx0lr5DWAGumBiEYQ)


As much as I research online and refer to the biblical [ESLII](https://web.stanford.edu/~hastie/Papers/ESLII.pdf), the theory doesn't seem settled.



A useful approach seems to be to bootstrap residuals after fitting mixed effects models. But it still requires specifying all the different kinds of effects. So Reverend Bayes strikes back - encoding our beliefs is needed although we might dress it up as mixed effects modelling or hide it behind parametric models.

Having said that - there are a variety of excellent ideas from [Bradley Efron](http://statweb.stanford.edu/~ckirby/brad/papers/), but again the ideas doesn't seem to have propagated to the application domain widely. (Assuming that being battle tested in open source competitions is  the way to verify the validity of theories.)

Great. Research. Topic.