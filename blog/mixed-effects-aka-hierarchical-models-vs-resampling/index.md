<!--
.. title: Mixed Effects (aka Hierarchical Models) vs Resampling?
.. slug: mixed-effects-aka-hierarchical-models-vs-resampling
.. date: 2019-10-08 21:37:33 UTC-04:00
.. tags: 
.. category: 
.. link: 
.. description: 
.. type: text
-->

Investigating fixed effects, random effects, mixed effects I felt queasy having to remember all these terms. It reminded me of [lasso & ridge regression or L1 & L2](https://stats.stackexchange.com/questions/200416/is-regression-with-l1-regularization-the-same-as-lasso-and-with-l2-regularizati) - naming concepts in statistics often feel unnecessarily complicated compared to computer science. 

This [post](https://statmodeling.stat.columbia.edu/2005/01/25/why_i_dont_use/) from Andrew Gelman made me think of mirror universes from the Star Trek Genre.

![](https://wwwimage-secure.cbsstatic.com/base/files/cea5c227c75c9531_dsc_mirror_georgious.jpg)

It's just so much nicer to think of all these effects as just being generated by hierarchical models with different hyperparameters on the priors. Having to remember the whole sequence of `* effects` models can be exhausting before even getting to the analysis.

His point holds, many frequentist family models are just one or other way of saying things that might naturally be framed as Bayesian problems. This resonates particularly well with mixed effects and hierarhical modelling.

![](https://i.imgflip.com/3craxc.jpg)


What has me interested, is if it's possible to model the fixed and random effects, or hierarhical model of feature weights through re-sampling strategies. I've never seen that done before.

Great. Research. Topic.