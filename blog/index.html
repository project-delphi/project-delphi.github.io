<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Ravi Kalia's Blog">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Ravi Kalia Blog</title>
<link href="../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../rss.xml">
<link rel="canonical" href="https://project-delphi.github.io/blog/">
<link rel="next" href="index-1.html" type="text/html">
<!--[if lt IE 9]><script src="../assets/js/html5.js"></script><![endif]--><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/latest/css/font-awesome.min.css">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-expand-md static-top mb-4
navbar-dark bg-dark
"><div class="container">
<!-- This keeps the margins nice -->
        <a class="navbar-brand" href="https://project-delphi.github.io/">

            <span id="blog-title">Ravi Kalia Blog</span>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="bs-navbar">
            <ul class="navbar-nav mr-auto">
<li class="nav-item">
<a href="../index.html" class="nav-link">Home</a>
                </li>
<li class="nav-item">
<a href="../contact/index.html" class="nav-link">Contact</a>
                </li>
<li class="nav-item">
<a href="../talks/index.html" class="nav-link">Talks</a>
                </li>
<li class="nav-item">
<a href="../publications/index.html" class="nav-link">Publications</a>
                </li>
<li class="nav-item">
<a href="../archive.html" class="nav-link">Blog</a>
                </li>
<li class="nav-item">
<a href="../categories/" class="nav-link">Tags</a>

                
            </li>
</ul>
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        

    


    
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="jupyter-docker-stacks/" class="u-url">Jupyter Docker Stacks</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Ravi Kalia
            </span></p>
            <p class="dateline">
            <a href="jupyter-docker-stacks/" rel="bookmark">
            <time class="published dt-published" datetime="2019-10-21T06:25:28-04:00" itemprop="datePublished" title="2019-10-21">2019-10-21</time></a>
            </p>
                <p class="commentline">
        
    <a href="jupyter-docker-stacks/#disqus_thread" data-disqus-identifier="cache/posts/jupyter-docker-stacks.html">Comments</a>


        </p>
</div>
    </header><div class="e-content entry-content">
    <div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Jupyter-Docker-Stacks">Jupyter Docker Stacks<a class="anchor-link" href="jupyter-docker-stacks/#Jupyter-Docker-Stacks">¶</a>
</h2>
<h3 id="DevOps">DevOps<a class="anchor-link" href="jupyter-docker-stacks/#DevOps">¶</a>
</h3>
<p>I have about 7 years of experience with DevOps methodology. It’s moved so fast and keeps going that early experiences with Chef, Ansible and earlier versions of Docker seem irrelevant. One sticking point I remember is the introduction of Docker and how it affected developers on Apple appliances. The Mac operating systems (OSX, macOS) have traditionally not played well with Docker.</p>
<p><img src="http://blog.adnansiddiqi.me/wp-content/uploads/2018/12/docker_logo.png" alt=""></p>
<p>However, Docker and DevOps generally allow careful dependency management. This is important particularly as I recently saw <a href="https://en.wikipedia.org/wiki/Dependency_hell">Dependency Hell</a>, and probably not for the last time. Reproducible results are a must and not a nice to have. Dependency hell really gets in the way of that.</p>
<p>As I mentioned Docker has traditionally played so slow on Apple products as to be an anti-pattern.</p>
<p><img src="https://www.tjohearn.com/wordpress/wp-content/uploads/2018/02/fire_whale-600x310.jpg" alt=""></p>
<p>This is do with how persistent data has been shared between Mac and running docker containers - very slowly using a concept of volumes. Let’s explain this below.</p>
<h3 id="Darwin-Is-Not-Linux">Darwin Is Not Linux<a class="anchor-link" href="jupyter-docker-stacks/#Darwin-Is-Not-Linux">¶</a>
</h3>
<p>There’s a long story about how Steve Jobs resurrected Apple. As a precursor he was involved in Next computers which developed a unix like OS called Darwin. In fact Darwin is a fork of BSD - Berkeley Software Distribution - itself based on UNIX. Linux meanwhile is a different OS, inspired by UNIX.</p>
<p>Docker relies on a linux-containers, and runs lightweight and fast in them. Apple OS’es don’t have linux-containers. Hence to run Docker on Apple and Microsoft has needed a VM of Linux - usually VirtualBox or VMWare.</p>
<p>In the past, using Docker on a Mac needed installing a specific version of VM software and hoping it would work well with Docker. This VM is the reason for the slowness Docker, in particular read/writes, on Apple.</p>
<p>So much so, that hackernews and reddit have been full of the anti-pattern of Docker on Apple.  This is because Docker has to talk to the VM which then talks to Apple OS and then talks to the hardware. There is the slowness.</p>
<h3 id="File-I/O">File I/O<a class="anchor-link" href="jupyter-docker-stacks/#File-I/O">¶</a>
</h3>
<p>The major slowness is observed when there is file I/O between the docker instance and the host OS. Docker abstracts the concept of read/writing between the host OS (in our case Apple) and the Docker instance as volumes. Volumes link directories in the two.</p>
<h3 id="Docker-Toolbox">Docker Toolbox<a class="anchor-link" href="jupyter-docker-stacks/#Docker-Toolbox">¶</a>
</h3>
<p>Apart from the slowness, the other issue has been getting a VM software to run on Apple. Docker released Docker Toolbox, which packages VirtualBox and Docker for legacy Apple and Windows OS’es - such as OSX.</p>
<p>This takes some of the pain out of installation and configuration. However latency remains pretty bad.</p>
<h3 id="Docker-For-Mac">Docker For Mac<a class="anchor-link" href="jupyter-docker-stacks/#Docker-For-Mac">¶</a>
</h3>
<p>There’s a new tool called Docker for Mac. This is making use of macOS container technologies directly and removes the need for a guest linux VM.</p>
<p>I’ve been running it and can attest that it is more lightweight and my Mac doesn’t sound like an airplane taking off with Docker running anymore.</p>
<h3 id="Volumes-are-now-better">Volumes are now better<a class="anchor-link" href="jupyter-docker-stacks/#Volumes-are-now-better">¶</a>
</h3>
<p>There’s been some clever work with volumes. delegated status allows the communication between Docker instances and macOS to run faster - still not as fast as linux containers, but much better than before.</p>
<h4 id="VS-Code-dials-into-Docker-Instances">VS Code dials into Docker Instances<a class="anchor-link" href="jupyter-docker-stacks/#VS-Code-dials-into-Docker-Instances">¶</a>
</h4>
<h4 id="NFS-is-coming">NFS is coming<a class="anchor-link" href="jupyter-docker-stacks/#NFS-is-coming">¶</a>
</h4>
<p>Back to Scientific Computing!</p>
<h3 id="Jupyter-Docker-Stacks">Jupyter Docker Stacks<a class="anchor-link" href="jupyter-docker-stacks/#Jupyter-Docker-Stacks">¶</a>
</h3>
<h4 id="joyvan">joyvan<a class="anchor-link" href="jupyter-docker-stacks/#joyvan">¶</a>
</h4>
<h4 id="Persisting-Data">Persisting Data<a class="anchor-link" href="jupyter-docker-stacks/#Persisting-Data">¶</a>
</h4>
<h3 id="Docker-Compose">Docker Compose<a class="anchor-link" href="jupyter-docker-stacks/#Docker-Compose">¶</a>
</h3>
<h4 id="Directory-Structure">Directory Structure<a class="anchor-link" href="jupyter-docker-stacks/#Directory-Structure">¶</a>
</h4>
<p><del>I may as well make explicit my assumption about the directory (not folder - this is *nix) structure assumed for development. This will feed into how volumes are shared in the <code>docker-compose.yml</code> file.</del></p>
<div class="highlight"><pre><span></span>Code
├── github.com
├── gitlab.com
└── throwaway
</pre></div>
<p>However, let’s scratch that. If we trust users to run  docker-compose files from inside their projects then we shouldn’t have record how their directories are laid out. Just specifying that we wish to mount/delegate the current directory to the docker instance's <code>jovyan</code> users work directory is enough.</p>
<p>Example Docker File</p>
<div class="highlight"><pre><span></span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Links">Links<a class="anchor-link" href="jupyter-docker-stacks/#Links">¶</a>
</h3>
<p>Some links I found useful in composing this post:</p>
<ul>
<li>
<p><a href="https://unsupervisedpandas.com/data-science/docker-for-data-science/">https://unsupervisedpandas.com/data-science/docker-for-data-science/</a></p>
</li>
<li>
<p><a href="https://docs.docker.com/compose/gettingstarted/">https://docs.docker.com/compose/gettingstarted/</a></p>
</li>
<li>
<p><a href="https://docs.docker.com/docker-for-mac/install/">https://docs.docker.com/docker-for-mac/install/</a></p>
</li>
<li>
<p><a href="https://docs.docker.com/compose/compose-file/#caching-options-for-volume-mounts-docker-for-mac">https://docs.docker.com/compose/compose-file/#caching-options-for-volume-mounts-docker-for-mac</a></p>
</li>
<li>
<p><a href="https://vivait.co.uk/labs/docker-for-mac-performance-using-nfs">https://vivait.co.uk/labs/docker-for-mac-performance-using-nfs</a></p>
</li>
<li>
<p><a href="https://stackoverflow.com/questions/43383276/how-does-docker-run-a-linux-kernel-under-macos-host">https://stackoverflow.com/questions/43383276/how-does-docker-run-a-linux-kernel-under-macos-host</a></p>
</li>
<li>
<p><a href="https://medium.com/fundbox-engineering/overview-d3759e83969c">https://medium.com/fundbox-engineering/overview-d3759e83969c</a></p>
</li>
<li>
<p><a href="https://spin.atomicobject.com/2019/10/14/docker-slow-mounted-volumes/">https://spin.atomicobject.com/2019/10/14/docker-slow-mounted-volumes/</a></p>
</li>
<li>
<p><a href="https://engageinteractive.co.uk/blog/making-docker-faster-on-mac">https://engageinteractive.co.uk/blog/making-docker-faster-on-mac</a></p>
</li>
<li>
<p><a href="https://blog.codeship.com/docker-for-windows-linux-and-mac/">https://blog.codeship.com/docker-for-windows-linux-and-mac/</a></p>
</li>
<li>
<p><a href="https://en.wikipedia.org/wiki/Berkeley_Software_Distribution">https://en.wikipedia.org/wiki/Berkeley_Software_Distribution</a></p>
</li>
<li>
<p><a href="https://towardsdatascience.com/jupyter-data-science-stack-docker-in-under-15-minutes-19d8f822bd45">https://towardsdatascience.com/jupyter-data-science-stack-docker-in-under-15-minutes-19d8f822bd45</a></p>
</li>
<li>
<p><a href="https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html">https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html</a></p>
</li>
<li>
<p><a href="https://github.com/stefanproell/jupyter-notebook-docker-compose">https://github.com/stefanproell/jupyter-notebook-docker-compose</a></p>
</li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="on-robust-ml-production-systems-maybe/" class="u-url">On Robust ML Production Systems, Maybe</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Ravi Kalia
            </span></p>
            <p class="dateline">
            <a href="on-robust-ml-production-systems-maybe/" rel="bookmark">
            <time class="published dt-published" datetime="2019-10-15T20:29:57-04:00" itemprop="datePublished" title="2019-10-15">2019-10-15</time></a>
            </p>
                <p class="commentline">
        
    <a href="on-robust-ml-production-systems-maybe/#disqus_thread" data-disqus-identifier="cache/posts/on-robust-ml-production-systems-maybe.html">Comments</a>


        </p>
</div>
    </header><div class="e-content entry-content">
    <div>
<p>Recently I was thinking of a recipe for robust ML systems in production. This was following from my talk at PyData Montreal discussing the same topic - where I alluded to building reflective culture and attitudes ingrained into the development process.</p>
<p>I drew a blank as a first concrete recipe; not just culture and ideas - since there's so much to making ML work in production.</p>
<p>Can this recipe be codified into a set of principles and working strategies which get the desired result? I'm thinking of an agile manifesto for ML in production, something with cool sounding acronyms.</p>
<p>First let's be clear about our objective.</p>
<p>What do we mean by "robust ML systems in production". Some desirable qualities that come to mind are:</p>
<ul>
<li>scalability under plausible increase of data dimensions</li>
<li>asynchronous scaling</li>
<li>sensible handling for unexpected data</li>
<li>graceful exit/handling of errors</li>
<li>fast response scaling under plausible request load</li>
<li>tolerance to network errors</li>
<li>tolerance of errors in training data</li>
<li>robust to changes in code development</li>
</ul>
<p>Some of these requirements overlap with agile methodologies for modern web development. Which makes sense, since most useful software makes use of the web. But in addition, there are guards to areas of brittleness in ML systems.</p>
<p>Much of this is discussed in the now famous 2015 <a href="https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf">Technical Debt Paper</a>.</p>
<p>What is needed is systems that work well enough when deployed live in the field - with web scale of data and networked requests.</p>
<p>I wrote in an <a href="https://project-delphi.github.io/blog/mlops-teams-vs-tools/">earlier post</a> how tools can help empower the individual developer. However, that's not the same as an ML in production manifesto.</p>
<p>Perhaps pruning a composite list from many practitioners and paper reviews.</p>
<p>How again was the <a href="https://agilemanifesto.org/">agile manifesto</a> generated all those years ago at a Ski resort in Utah?</p>
<p>Reflective. Practice.</p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="treatment-effects-on-continuous-targets-with-no-features/" class="u-url">Treatment Effects on Continuous Targets with No Features</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Ravi Kalia
            </span></p>
            <p class="dateline">
            <a href="treatment-effects-on-continuous-targets-with-no-features/" rel="bookmark">
            <time class="published dt-published" datetime="2019-10-14T21:11:00-04:00" itemprop="datePublished" title="2019-10-14">2019-10-14</time></a>
            </p>
                <p class="commentline">
        
    <a href="treatment-effects-on-continuous-targets-with-no-features/#disqus_thread" data-disqus-identifier="cache/posts/treatment-effects-on-continuous-targets-with-no-features.html">Comments</a>


        </p>
</div>
    </header><div class="e-content entry-content">
    <div>
<p>I found myself thinking about treatment effects on randomized small samples for continuous data (targets) with no features.</p>
<p>There's no need to worry about confounders since there are no features and we have randomizations - 🎲. Simpson's paradox doesn't apply when there are no features.</p>
<p>One might say that we are looking univariate continuous data from two or more different small samples. Small is relative, but less than a few thousand examples certainly causes noise in estimates for many kinds of univariate continuous distribution.</p>
<p>So what is the objective from a machine learning perspective? and what can be done?</p>
<p>Well, this could be cast as an unsupervised learning problem. Some possibilities are:</p>
<ul>
<li>
<p>use method of moments: compare empirical moments across samples. The problem is that this is sensitive to the random noise in the data generating process.</p>
</li>
<li>
<p>hypothesis test parametric fits: use sample sizes and asymptotic theory. This is limited because only simple parametric forms have known asymptotic properties - additionally they are only asymptotically true.</p>
</li>
<li>
<p>compare non-parametric density estimates: estimate densities for different samples. Doing straight eyeballing might be problematic though. Some good ways to try this are:</p>
<ul>
<li>sums of weighted observation centered kernels</li>
<li>Bayesian hierarchical mixtures of densities (which lends itself to clustering)</li>
</ul>
</li>
</ul>
<p>In particular there are many non-parametric chart and univariate statistic based approaches (Mann-Whitney-Wilcoxon, Anderson-Darling, Kolmogorov-Smirov, permutation test, Earth Mover's Distance, visually inspecting densities and more).</p>
<p>I suspect that any of these approaches are fine when the differences between samples are quite pronounced - but when the treatment effects are subtle but samples - it will be difficult to tell noise from genuine effects.</p>
<p>So a problem exists. We don't allow in our inference for data that is plausibly similar to what was actually observed. For a few different observations in one or other sample, our inferences can be reversed.</p>
<p>The remedies are to use Bayesian or Ensembling strategies to loosen a model's adherence to and enthusiasm for the data observed. If we had large samples (Yay! big data Yay!), then this is less necessary.</p>
<p>I'm quite excited to read up on Bayesian fields as a way to allow the data to breathe when making estimates of densities. 🧗🏾‍</p>
<p>An aside: As an undergrad, I suggested that Kolmogorov-Smirnov was mis-spelled to a Russian professor. He promptly corrected the spelling as:</p>
<p>колмогоров-смирнов.</p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="mixed-effects-aka-hierarchical-models-vs-resampling/" class="u-url">Mixed Effects (aka Hierarchical Models) vs Resampling?</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Ravi Kalia
            </span></p>
            <p class="dateline">
            <a href="mixed-effects-aka-hierarchical-models-vs-resampling/" rel="bookmark">
            <time class="published dt-published" datetime="2019-10-08T21:37:33-04:00" itemprop="datePublished" title="2019-10-08">2019-10-08</time></a>
            </p>
                <p class="commentline">
        
    <a href="mixed-effects-aka-hierarchical-models-vs-resampling/#disqus_thread" data-disqus-identifier="cache/posts/mixed-effects-aka-hierarchical-models-vs-resampling.html">Comments</a>


        </p>
</div>
    </header><div class="e-content entry-content">
    <div>
<p>Investigating fixed effects, random effects, mixed effects I felt queasy having to remember all these terms. It reminded me of <a href="https://stats.stackexchange.com/questions/200416/is-regression-with-l1-regularization-the-same-as-lasso-and-with-l2-regularizati">lasso &amp; ridge regression or L1 &amp; L2</a> - naming concepts in statistics often feel unnecessarily complicated compared to computer science. </p>
<p>This <a href="https://statmodeling.stat.columbia.edu/2005/01/25/why_i_dont_use/">post</a> from Andrew Gelman made me think of mirror universes from the Star Trek Genre.</p>
<p><img alt="" src="https://wwwimage-secure.cbsstatic.com/base/files/cea5c227c75c9531_dsc_mirror_georgious.jpg"></p>
<p>It's just so much nicer to think of all these effects as just being generated by hierarchical models with different hyperparameters on the priors. Having to remember the whole sequence of <code>* effects</code> models can be exhausting before even getting to the analysis.</p>
<p>His point holds, many frequentist family models are just one or other way of saying things that might naturally be framed as Bayesian problems. This resonates particularly well with mixed effects and hierarhical modelling.</p>
<p><img alt="" src="https://i.imgflip.com/3craxc.jpg"></p>
<p>What has me interested, is if it's possible to model the fixed and random effects, or hierarhical model of feature weights through re-sampling strategies. I've never seen that done before.</p>
<p>This would open up a third mirror universe where resampling strategies could be used to approximate mixed effects/hierarchical models.</p>
<p><img alt="" src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQt1y4TKw9m_ojbyAIdC1UfuNfBvBknU9GvbKx0lr5DWAGumBiEYQ"></p>
<p>As much as I research online and refer to the biblical <a href="https://web.stanford.edu/~hastie/Papers/ESLII.pdf">ESLII</a>, the theory doesn't seem settled.</p>
<p>A useful approach seems to be to bootstrap residuals after fitting mixed effects models. But it still requires specifying all the different kinds of effects. So Reverend Bayes strikes back - encoding our beliefs is needed although we might dress it up as mixed effects modelling or hide it behind parametric models.</p>
<p>Having said that - there are a variety of excellent ideas from <a href="http://statweb.stanford.edu/~ckirby/brad/papers/">Bradley Efron</a>, but again the ideas doesn't seem to have propagated to the application domain widely. (Assuming that being battle tested in open source competitions is  the way to verify the validity of theories.)</p>
<p>Great. Research. Topic.</p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="the-new-york-bayesian-and-professor-ripley/" class="u-url">The New York Bayesian And Professor Ripley</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Ravi Kalia
            </span></p>
            <p class="dateline">
            <a href="the-new-york-bayesian-and-professor-ripley/" rel="bookmark">
            <time class="published dt-published" datetime="2019-10-06T21:25:01-04:00" itemprop="datePublished" title="2019-10-06">2019-10-06</time></a>
            </p>
                <p class="commentline">
        
    <a href="the-new-york-bayesian-and-professor-ripley/#disqus_thread" data-disqus-identifier="cache/posts/the-new-york-bayesian-and-professor-ripley.html">Comments</a>


        </p>
</div>
    </header><div class="e-content entry-content">
    <div>
<p>I found myself Googling for a refresher on hierarchical models and random effects approaches to weights that have their own distribution. The terms that kept occurring where:</p>
<ul>
<li>
<code>fixed</code> effects</li>
<li>
<code>random</code> effects</li>
<li>
<code>mixed</code> effects</li>
<li>Bayesian Hierarchical Models</li>
</ul>
<p>And then I remembered <code>main</code> effects and <code>interaction</code> effects. Feeling more confident in the terminology of both frequentist <code>random effects</code> and Bayesian <code>hierarchical models</code> - being two sides of the same coin, I felt quite pleased.</p>
<p>As I kept trawling, I came across a post from noted and prolific blogging Bayesian - <a href="http://www.stat.columbia.edu/~gelman/">Andrew Gelman</a>. He had a <a href="https://statmodeling.stat.columbia.edu/2011/12/17/ripley-on-model-selection-and-some-links-on-exploratory-model-analysis/">post</a> about model selection mentioning my doctoral supervisor <a href="http://www.stats.ox.ac.uk/~ripley/">Professor Ripley</a>. It was good, and a reference to a talk I had not seen - so many ideas now mainstream and well elucidated are in this paper.</p>
<p>I believe Google's search engine had linked my previous search history to this query. I confirmed that incognito, this same links do not appear.</p>
<p>Serendipity. In. Learning. To. Learn. From. Data.</p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="code-fragments-on-wikipedia/" class="u-url">Code Fragments On Wikipedia</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Ravi Kalia
            </span></p>
            <p class="dateline">
            <a href="code-fragments-on-wikipedia/" rel="bookmark">
            <time class="published dt-published" datetime="2019-10-04T10:49:16-04:00" itemprop="datePublished" title="2019-10-04">2019-10-04</time></a>
            </p>
                <p class="commentline">
        
    <a href="code-fragments-on-wikipedia/#disqus_thread" data-disqus-identifier="cache/posts/code-fragments-on-wikipedia.html">Comments</a>


        </p>
</div>
    </header><div class="e-content entry-content">
    <div>
<p>After I spoke at PyData Montreal about maintaining code quality in data science/machine learning - I showed a cleaned up code fragment for the PageRank algorithm in Python on <a href="https://en.wikipedia.org/wiki/PageRank">Wikipedia</a>.</p>
<p>It got me thinking. There really should be code guidelines and a major clean up effort in the wikipedia sections for Machine Learning/Statistics.</p>
<p>Something like a guidelines document for the major languages would be great. In addition, an effort to clean up code fragments on say the first 100 articles in Machine Learning - that's important.</p>
<p>Brainwave - couldn't this be part of course requirements for graduate courses in various departments worldwide 📚. This would be a great learning exercise and help the broader community.</p>
<p>Why do this? Wikipedia is a resource for the whole world. The more people in scientific computing that are exposed to good coding guidelines, the healthier our community will be.</p>
<p>Open. Source. Community. 🌱</p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="when-is-causality-important/" class="u-url">When Is Causality Important</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Ravi Kalia
            </span></p>
            <p class="dateline">
            <a href="when-is-causality-important/" rel="bookmark">
            <time class="published dt-published" datetime="2019-09-29T16:34:44-04:00" itemprop="datePublished" title="2019-09-29">2019-09-29</time></a>
            </p>
                <p class="commentline">
        
    <a href="when-is-causality-important/#disqus_thread" data-disqus-identifier="cache/posts/when-is-causality-important.html">Comments</a>


        </p>
</div>
    </header><div class="e-content entry-content">
    <div>
<p>A data scientist works on three types of problems:</p>
<ol>
<li>Prediction</li>
<li>Description</li>
<li>Causality</li>
</ol>
<p>I've been thinking of when it is that causality is important. The reason is for quite sometime I didn't put much thought into the area - it is messy. I had been sold on the statistical perspective that correlation is not causation, only controlled randomized experiments with enough confounders could determine causality <a href="https://arxiv.org/abs/1804.10846">[1]</a>.</p>
<p>Instead, I focussed on prediction - using regularization to press down on correlated (and possibly causal) features and weights so that deciding to leave features in or out didn't really matter. This strategy has worked combined with robustness techniques (such as bootstrap ensembling or randomized dropout) across many applications using learning algorithms.</p>
<p><img alt="" src="https://i.imgflip.com/223wf5.jpg"></p>
<p>Regularizing is as if the <del>features</del> weights on features are flattened so that only the most essential and truly impactful are allowed to affect the outcome - like a flattened statue, the essence can still be determined.</p>
<p>This prediction focus matters when there is observational data and the objective is to query a model and return a "best" prediction on a target. Indeed, much of the billions in Machine Learning have been spent on getting prediction right.</p>
<h3>When does causality matter to an organization?</h3>
<p>Well it seems that it matters when the features can be manipulated. This is also referred to as applying treatments, having controls and considering regimes.</p>
<p>More importantly, if these features have high cost (such as appliance choice in a cloud server or deployment of physical/financial resources) then it makes sense to focus on causality.</p>
<p><img alt="" src="http://www.kappit.com/img/pics/201602_1229_ihdaf_sm.jpg"></p>
<p>It depends on the context as to what cost is unbearable (reputation, dollar amount, ethical concerns) so that manipulating features becomes desirable.</p>
<p>This might be referred to as an asset allocation strategy in some fields of study.</p>
<p><img alt="" src="https://imgflip.com/i/3c0wbp"></p>
<p>One is usually looking for the best way to distribute resources based on causal inference. By estimating the counterfactual - the distribution of not applying a treatment (manipulating features) -  to optimize the target of future examples - probablistically, since deterministic targets seldom occur in business or nature.</p>
<p>This is only possible because we make assumptions on the kind of relationship that might hold going from a controlled feature vs a treatment feature to the target. There are three schools making different assumptions:</p>
<ol>
<li>Statistics using Propensity Matching</li>
<li>Computer Science using Structural Equation DAGs</li>
<li>Econometrics using Instrument Variables</li>
</ol>
<p>The group of assumptions made affect the probability distribution of the target and hence the decisions made. This in part is why causal reasoning does not have clean well understood modelling approaches, unlike prediction.</p>
<p>Different. Assumptions. Generate. Different. Distributions.</p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="mlops-teams-vs-tools/" class="u-url">MLOps Teams or Tools</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Ravi Kalia
            </span></p>
            <p class="dateline">
            <a href="mlops-teams-vs-tools/" rel="bookmark">
            <time class="published dt-published" datetime="2019-09-26T13:47:04-04:00" itemprop="datePublished" title="2019-09-26">2019-09-26</time></a>
            </p>
                <p class="commentline">
        
    <a href="mlops-teams-vs-tools/#disqus_thread" data-disqus-identifier="cache/posts/mlops-teams-vs-tools.html">Comments</a>


        </p>
</div>
    </header><div class="e-content entry-content">
    <div>
<p>Yesterday, I spoke at PyData Montreal. It was a lot of fun to discuss MLOps - particularly the parallels to DevOps advancement. </p>
<p>I spoke to an individual about a contradiction in my talk. I discussed the friction in taking data products to production.</p>
<p><img alt="" src="https://i2.wp.com/www.developermemes.com/wp-content/uploads/2013/12/Worked-Fine-In-Dev-Ops-Problem-Now.jpg?fit=400%2C299"></p>
<p>I first talked about how building a team with:</p>
<ul>
<li>Data Scientists/ML Researchers</li>
<li>ML Engineers/Software Engineers</li>
<li>Deployment Specialists</li>
</ul>
<p>is one way to scale product development - the other being a unicorn superhero with all the skills combined. However I also noted the issue with ownership and understanding of the product can get muddled. Translating the product in intermediate steps can lose intention from product ideation to deployment.</p>
<p>I also ended with a quote:</p>
<blockquote>
<p>People who write the models/algorithms should be the ones to implement them.</p>
</blockquote>
<p>So there's the contradiction. How can one person have all these skills and qualities. Well plainly, they can't.</p>
<p><img alt="" src="https://miro.medium.com/max/550/1*A_uvkhhEuvh1Jj_rDy1DYA.jpeg"></p>
<p>After some thinking, this conflict can be resolved as has been happening with software development - particularly web development. We need <em>easy-to-use tools</em> in an integrated workflow that can be managed by a team of software/ml engineers who can continuously iterate in short cycles with <em>automated guardrails</em>. With the right workflow, it should become very difficult if not impossible to deploy failing ML code. Then we just need extremely focussed short cycles of development.</p>
<p>Once that happens, individual members of teams will rotate between roles and get experience (possibly mastery) across the board in ML development.</p>
<p>So using easy to use performant tools an ML developer can be augmented - much like Iron Man with his suit.</p>
<p><img alt="" src="http://www.memesboy.com/wp-content/uploads/2018/08/Perhaps-But-Im-Also-Iron-Man-Meme.jpg"></p>
<p>Let's remember that not all web developers have embraced Agile CI/CD. In the same way, not all ML deployment will be following such a model. However, it should become increasingly uncommon to see long brittle development cycles.</p>
<p>Developer. Velocity. Matters.</p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="jupyter-notebook-vs-html/" class="u-url">Jupyter Notebook vs HTML</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Ravi Kalia
            </span></p>
            <p class="dateline">
            <a href="jupyter-notebook-vs-html/" rel="bookmark">
            <time class="published dt-published" datetime="2019-09-24T14:18:47-04:00" itemprop="datePublished" title="2019-09-24">2019-09-24</time></a>
            </p>
                <p class="commentline">
        
    <a href="jupyter-notebook-vs-html/#disqus_thread" data-disqus-identifier="cache/posts/embedding-htmlcss-in-jupyter-notebooks.html">Comments</a>


        </p>
</div>
    </header><div class="e-content entry-content">
    <div>
<p>I recently found myself putting together a presentation for PyData. I was excited for the opportunity to use the <a href="https://rise.readthedocs.io/en/maint-5.5/">rise</a> extension for jupyter notebooks.</p>
<p>All seemed well until I decided to style using html (Headers, cute icon, that kind of stuff) into some markdown cells.</p>
<p>Turns out that although markdown is a superset of html, jupyter markdown cells don't render html.</p>
<p>I also tried render in google sides and reveal.js - no joy.</p>
<p>In the end, I found an even more convoluted solution. I made all my slides as styled html pages. Then I took screenshots (yes screenshots!) and embedded screenshot images into markdown cells marked as slides with rise.</p>
<p>This has to be an example of glue code!</p>
<p>Painful. Experience.</p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="why-is-git-so-hard-to-understand/" class="u-url">Why Is Git So Hard To Understand?</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Ravi Kalia
            </span></p>
            <p class="dateline">
            <a href="why-is-git-so-hard-to-understand/" rel="bookmark">
            <time class="published dt-published" datetime="2019-09-18T19:56:10-04:00" itemprop="datePublished" title="2019-09-18">2019-09-18</time></a>
            </p>
                <p class="commentline">
        
    <a href="why-is-git-so-hard-to-understand/#disqus_thread" data-disqus-identifier="cache/posts/why-is-git-so-hard-to-understand.html">Comments</a>


        </p>
</div>
    </header><div class="e-content entry-content">
    <div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Why-is-Git-so-hard-to-understand?">Why is Git so hard to understand?<a class="anchor-link" href="why-is-git-so-hard-to-understand/#Why-is-Git-so-hard-to-understand?">¶</a>
</h2>
<p><img src="https://miro.medium.com/max/1575/0*0Xfaz0bvLpRksBv5." alt=""></p>
<p>I've been writing a series of posts on Git, with the aim of using them to train data scientists on good practices for robust solutions that can be productionized with little effort; increasing developer/data scientist velocity.</p>
<h3 id="Why-Git?">Why Git?<a class="anchor-link" href="why-is-git-so-hard-to-understand/#Why-Git?">¶</a>
</h3>
<p>Git is the standard DVCS tool for groups of software professionals collaborating. To build robust projects that can be iterated and ideated on, git is the de-facto standard. It was initiated by <a href="https://github.com/torvalds">Linus Torvalds</a> which helped its adoption.</p>
<h3 id="What's-wrong-with-(G)it?">What's wrong with (G)it?<a class="anchor-link" href="why-is-git-so-hard-to-understand/#What's-wrong-with-(G)it?">¶</a>
</h3>
<p>With a little googling, I've found dozens of posts accepting that even seasoned developers can be puzzled by it's intricacies; git is widely recognized as difficult to use - <a href="https://spderosso.github.io/onward13.pdf">[1]</a>. Users find some working patterns and cling to them when developing - googling when things get out of hand, usually relying on <code>git reset --hard</code> and <code>git reflog</code> to get out of problems.</p>
<h3 id="No-Object-Model">No Object Model<a class="anchor-link" href="why-is-git-so-hard-to-understand/#No-Object-Model">¶</a>
</h3>
<p>Git doesn't have a clean API with an object model. Git evolved somewhat organically as needs arose. Although some efforts were made to abstract out what was happening, it somehow got all mixed up.</p>
<h3 id="Plumbing,-Porcelain-and-Poop">Plumbing, Porcelain and Poop<a class="anchor-link" href="why-is-git-so-hard-to-understand/#Plumbing,-Porcelain-and-Poop">¶</a>
</h3>
<p>The original idea had been there would be low-level commands (for developers of git) were not for users, and instead they would use higher-level porcelain commands. Instead, as users became familiar and had various use cases, they dropped down into the low-level plumbing and the porcelain commands just didn't have enough expressive power. So now we have a poop-like (following plumbing and porcelain) situation where the ways to interact with git are so numerous and involved, that it's hard to keep a handle on.</p>
<h3 id="Data-Structures">Data Structures<a class="anchor-link" href="why-is-git-so-hard-to-understand/#Data-Structures">¶</a>
</h3>
<p>Git makes use of, and inadvertently exposes several data structures - which are never thoroughly explained and often not needed for new users - adding to the mystique surrounding it.</p>
<h4 id="The-Git-Graph-Model">The Git Graph Model<a class="anchor-link" href="why-is-git-so-hard-to-understand/#The-Git-Graph-Model">¶</a>
</h4>
<p>The git graph model is a great way to understand how branches, commits and navigation work. However it relates to other concepts such as working tree, branch name pointers, HEAD and branch tips - all of which need time to be understood.</p>
<h4 id="Blobs">Blobs<a class="anchor-link" href="why-is-git-so-hard-to-understand/#Blobs">¶</a>
</h4>
<p>The Blobs are object stores that contain the contents of files. They are named using the contents of the file and a hashing algorithm.</p>
<h4 id="SHAs">SHAs<a class="anchor-link" href="why-is-git-so-hard-to-understand/#SHAs">¶</a>
</h4>
<p>The hashing algorithm is applied to git commits and blobs contents. It's not widely used by users.</p>
<h3 id="Naming-of-Commands">Naming of Commands<a class="anchor-link" href="why-is-git-so-hard-to-understand/#Naming-of-Commands">¶</a>
</h3>
<p>The naming of git commands is very different from other VCS systems and so can confuse users from other VCS systems.</p>
<h3 id="Distributed-Version-Control">Distributed Version Control<a class="anchor-link" href="why-is-git-so-hard-to-understand/#Distributed-Version-Control">¶</a>
</h3>
<p>The distributed in git's DVCS is the major innovation vs other VCS systems.</p>
<h3 id="Lack-of-Consistency-In-Command-Names">Lack of Consistency In Command Names<a class="anchor-link" href="why-is-git-so-hard-to-understand/#Lack-of-Consistency-In-Command-Names">¶</a>
</h3>
<p>The git commands have irregular names and flags, so that the same semantic operations have different names. This parable from <a href="https://www.quora.com/Why-is-Git-so-hard-to-learn">quora</a> is quite telling:</p>
<blockquote>
<p>A novice was learning at the feet of Master Git. At the end of the lesson he looked through his notes and said, “Master, I have a few questions. May I ask them?”</p>
<p>Master Git nodded.</p>
<p>“How can I view a list of all tags?”</p>
<p>“git tag”, replied Master Git.</p>
<p>“How can I view a list of all remotes?”</p>
<p>“git remote -v”, replied Master Git.</p>
<p>“How can I view a list of all branches?”</p>
<p>“git branch -a”, replied Master Git.</p>
<p>“And how can I view the current branch?”</p>
<p>“git rev-parse --abbrev-ref HEAD”, replied Master Git.</p>
<p>“How can I delete a remote?”</p>
<p>“git remote rm”, replied Master Git.</p>
<p>“And how can I delete a branch?”</p>
<p>“git branch -d”, replied Master Git.</p>
<p>The novice thought for a few moments, then asked: “Surely some of these could be made more consistent, so as to be easier to remember in the heat of coding?”</p>
<p>Master Git snapped his fingers. A hobgoblin entered the room and ate the novice alive. In the afterlife, the novice was enlightened.</p>
</blockquote>
<h3 id="Conclusion">Conclusion<a class="anchor-link" href="why-is-git-so-hard-to-understand/#Conclusion">¶</a>
</h3>
<p>Git is a genius piece of software. It is probably unnecessarily complicated and unwieldy, but given it's wide user base - we're stuck with it for some time to come. There are some efforts to produce a cleaner porcelain shell, such as <a href="https://github.com/sdg-mit/gitless">gitless</a> - they just haven't got enough traction for most organizations.</p>
<p>Seems like it's ripe for disruption.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
</div>
    </div>
    </article>
</div>

        <ul class="pager postindexpager clearfix">
<li class="next"><a href="index-1.html" rel="next">Older posts</a></li>
        </ul>
<script>var disqus_shortname="https-project-delphi-github-io";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" integrity="sha256-SDRP1VVYu+tgAGKhddBSl5+ezofHKZeI+OzxakbIe/Y=" crossorigin="anonymous"></script><script type="text/x-mathjax-config">
        MathJax.Hub.Config({tex2jax: {inlineMath: [['$latex ','$'], ['\\(','\\)']]}});
        </script><!--End of body content--><footer id="footer"><div class="text-center">
<p>
<span class="fa-stack fa-2x">
  <a href="https://twitter.com/ravkalia1">
    <i class="fa fa-circle fa-stack-2x"></i>
    <i class="fa fa-twitter fa-inverse fa-stack-1x"></i>
  </a>
</span>
<span class="fa-stack fa-2x">
  <a href="https://github.com/project-delphi">
    <i class="fa fa-circle fa-stack-2x"></i>
    <i class="fa fa-github fa-inverse fa-stack-1x"></i>
  </a>
</span>
<span class="fa-stack fa-2x">
  <a href="https://www.linkedin.com/in/ravi-kalia-phd">
    <i class="fa fa-circle fa-stack-2x"></i>
    <i class="fa fa-linkedin fa-inverse fa-stack-1x"></i>
  </a>
</span>
<span class="fa-stack fa-2x">
  <a href="mailto:ravkalia@gmail.com">
    <i class="fa fa-circle fa-stack-2x"></i>
    <i class="fa fa-envelope fa-inverse fa-stack-1x"></i>
  </a>
</span>
</p>
<p>
  Contents © 2019  <a href="mailto:ravkalia@gmail.com">Ravi Kalia</a>
  —
  
  —
  Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a>
</p>
</div>

            
        </footer>
</div>
</div>


        <script src="../assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script>
</body>
</html>
