<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Ravi Kalia Blog</title><link>https://project-delphi.github.io/</link><description>Ravi Kalia's Blog</description><atom:link href="https://project-delphi.github.io/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents ¬© 2019 &lt;a href="mailto:ravkalia@gmail.com"&gt;Ravi Kalia&lt;/a&gt; </copyright><lastBuildDate>Sat, 05 Oct 2019 11:08:51 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Code Fragments On Wikipedia</title><link>https://project-delphi.github.io/blog/code-fragments-on-wikipedia/</link><dc:creator>Ravi Kalia</dc:creator><description>&lt;div&gt;&lt;p&gt;After I spoke at PyData Montreal about maintaining code quality in data science/machine learning - I showed a cleaned up code fragment for the PageRank algorithm in Python on &lt;a href="https://en.wikipedia.org/wiki/PageRank"&gt;Wikipedia&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It got me thinking. There really should be code guidelines and a major clean up effort in the wikipedia sections for Machine Learning/Statistics.&lt;/p&gt;
&lt;p&gt;Something like a guidelines document for the major languages would be great. In addition, an effort to clean up code fragments on say the first 100 articles in Machine Learning - that's important.&lt;/p&gt;
&lt;p&gt;Brainwave - couldn't this be part of course requirements for graduate courses in various departments worldwide üìö. This would be a great learning exercise and help the broader community.&lt;/p&gt;
&lt;p&gt;Why do this? Wikipedia is a resource for the whole world. The more people in scientific computing that are exposed to good coding guidelines, the healthier our community will be.&lt;/p&gt;
&lt;p&gt;Open. Source. Community. üå±&lt;/p&gt;&lt;/div&gt;</description><guid>https://project-delphi.github.io/blog/code-fragments-on-wikipedia/</guid><pubDate>Fri, 04 Oct 2019 14:49:16 GMT</pubDate></item><item><title>When Is Causality Important</title><link>https://project-delphi.github.io/blog/when-is-causality-important/</link><dc:creator>Ravi Kalia</dc:creator><description>&lt;div&gt;&lt;p&gt;A data scientist works on three types of problems:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Prediction&lt;/li&gt;
&lt;li&gt;Description&lt;/li&gt;
&lt;li&gt;Causality&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I've been thinking of when it is that causality is important. The reason is for quite sometime I didn't put much thought into the area - it is messy. I had been sold on the statistical perspective that correlation is not causation, only controlled randomized experiments with enough confounders could determine causality &lt;a href="https://arxiv.org/abs/1804.10846"&gt;[1]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Instead, I focussed on prediction - using regularization to press down on correlated (and possibly causal) features and weights so that deciding to leave features in or out didn't really matter. This strategy has worked combined with robustness techniques (such as bootstrap ensembling or randomized dropout) across many applications using learning algorithms.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://i.imgflip.com/223wf5.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Regularizing is as if the &lt;del&gt;features&lt;/del&gt; weights on features are flattened so that only the most essential and truly impactful are allowed to affect the outcome - like a flattened statue, the essence can still be determined.&lt;/p&gt;
&lt;p&gt;This prediction focus matters when there is observational data and the objective is to query a model and return a "best" prediction on a target. Indeed, much of the billions in Machine Learning have been spent on getting prediction right.&lt;/p&gt;
&lt;h3&gt;When does causality matter to an organization?&lt;/h3&gt;
&lt;p&gt;Well it seems that it matters when the features can be manipulated. This is also referred to as applying treatments, having controls and considering regimes.&lt;/p&gt;
&lt;p&gt;More importantly, if these features have high cost (such as appliance choice in a cloud server or deployment of physical/financial resources) then it makes sense to focus on causality.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.kappit.com/img/pics/201602_1229_ihdaf_sm.jpg"&gt;&lt;/p&gt;
&lt;p&gt;It depends on the context as to what cost is unbearable (reputation, dollar amount, ethical concerns) so that manipulating features becomes desirable.&lt;/p&gt;
&lt;p&gt;This might be referred to as an asset allocation strategy in some fields of study.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://imgflip.com/i/3c0wbp"&gt;&lt;/p&gt;
&lt;p&gt;One is usually looking for the best way to distribute resources based on causal inference. By estimating the counterfactual - the distribution of not applying a treatment (manipulating features) -  to optimize the target of future examples - probablistically, since deterministic targets seldom occur in business or nature.&lt;/p&gt;
&lt;p&gt;This is only possible because we make assumptions on the kind of relationship that might hold going from a controlled feature vs a treatment feature to the target. There are three schools making different assumptions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Statistics using Propensity Matching&lt;/li&gt;
&lt;li&gt;Computer Science using Structural Equation DAGs&lt;/li&gt;
&lt;li&gt;Econometrics using Instrument Variables&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The group of assumptions made affect the probability distribution of the target and hence the decisions made. This in part is why causal reasoning does not have clean well understood modelling approaches, unlike prediction.&lt;/p&gt;
&lt;p&gt;Different. Assumptions. Generate. Different. Distributions.&lt;/p&gt;&lt;/div&gt;</description><guid>https://project-delphi.github.io/blog/when-is-causality-important/</guid><pubDate>Sun, 29 Sep 2019 20:34:44 GMT</pubDate></item><item><title>MLOps Teams or Tools</title><link>https://project-delphi.github.io/blog/mlops-teams-vs-tools/</link><dc:creator>Ravi Kalia</dc:creator><description>&lt;div&gt;&lt;p&gt;Yesterday, I spoke at PyData Montreal. It was a lot of fun to discuss MLOps - particularly the parallels to DevOps advancement. &lt;/p&gt;
&lt;p&gt;I spoke to an individual about a contradiction in my talk. I discussed the friction in taking data products to production.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://i2.wp.com/www.developermemes.com/wp-content/uploads/2013/12/Worked-Fine-In-Dev-Ops-Problem-Now.jpg?fit=400%2C299"&gt;&lt;/p&gt;
&lt;p&gt;I first talked about how building a team with:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data Scientists/ML Researchers&lt;/li&gt;
&lt;li&gt;ML Engineers/Software Engineers&lt;/li&gt;
&lt;li&gt;Deployment Specialists&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;is one way to scale product development - the other being a unicorn superhero with all the skills combined. However I also noted the issue with ownership and understanding of the product can get muddled. Translating the product in intermediate steps can lose intention from product ideation to deployment.&lt;/p&gt;
&lt;p&gt;I also ended with a quote:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;People who write the models/algorithms should be the ones to implement them.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So there's the contradiction. How can one person have all these skills and qualities. Well plainly, they can't.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://miro.medium.com/max/550/1*A_uvkhhEuvh1Jj_rDy1DYA.jpeg"&gt;&lt;/p&gt;
&lt;p&gt;After some thinking, this conflict can be resolved as has been happening with software development - particularly web development. We need &lt;em&gt;easy-to-use tools&lt;/em&gt; in an integrated workflow that can be managed by a team of software/ml engineers who can continuously iterate in short cycles with &lt;em&gt;automated guardrails&lt;/em&gt;. With the right workflow, it should become very difficult if not impossible to deploy failing ML code. Then we just need extremely focussed short cycles of development.&lt;/p&gt;
&lt;p&gt;Once that happens, individual members of teams will rotate between roles and get experience (possibly mastery) across the board in ML development.&lt;/p&gt;
&lt;p&gt;So using easy to use performant tools an ML developer can be augmented - much like Iron Man with his suit.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.memesboy.com/wp-content/uploads/2018/08/Perhaps-But-Im-Also-Iron-Man-Meme.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Let's remember that not all web developers have embraced Agile CI/CD. In the same way, not all ML deployment will be following such a model. However, it should become increasingly uncommon to see long brittle development cycles.&lt;/p&gt;
&lt;p&gt;Developer. Velocity. Matters.&lt;/p&gt;&lt;/div&gt;</description><guid>https://project-delphi.github.io/blog/mlops-teams-vs-tools/</guid><pubDate>Thu, 26 Sep 2019 17:47:04 GMT</pubDate></item><item><title>Jupyter Notebook vs HTML</title><link>https://project-delphi.github.io/blog/jupyter-notebook-vs-html/</link><dc:creator>Ravi Kalia</dc:creator><description>&lt;div&gt;&lt;p&gt;I recently found myself putting together a presentation for PyData. I was excited for the opportunity to use the &lt;a href="https://rise.readthedocs.io/en/maint-5.5/"&gt;rise&lt;/a&gt; extension for jupyter notebooks.&lt;/p&gt;
&lt;p&gt;All seemed well until I decided to style using html (Headers, cute icon, that kind of stuff) into some markdown cells.&lt;/p&gt;
&lt;p&gt;Turns out that although markdown is a superset of html, jupyter markdown cells don't render html.&lt;/p&gt;
&lt;p&gt;I also tried render in google sides and reveal.js - no joy.&lt;/p&gt;
&lt;p&gt;In the end, I found an even more convoluted solution. I made all my slides as styled html pages. Then I took screenshots (yes screenshots!) and embedded screenshot images into markdown cells marked as slides with rise.&lt;/p&gt;
&lt;p&gt;This has to be an example of glue code!&lt;/p&gt;
&lt;p&gt;Painful. Experience.&lt;/p&gt;&lt;/div&gt;</description><guid>https://project-delphi.github.io/blog/jupyter-notebook-vs-html/</guid><pubDate>Tue, 24 Sep 2019 18:18:47 GMT</pubDate></item><item><title>Why Is Git So Hard To Understand?</title><link>https://project-delphi.github.io/blog/why-is-git-so-hard-to-understand/</link><dc:creator>Ravi Kalia</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Why-is-Git-so-hard-to-understand?"&gt;Why is Git so hard to understand?&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/why-is-git-so-hard-to-understand/#Why-is-Git-so-hard-to-understand?"&gt;¬∂&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;img src="https://miro.medium.com/max/1575/0*0Xfaz0bvLpRksBv5." alt=""&gt;&lt;/p&gt;
&lt;p&gt;I've been writing a series of posts on Git, with the aim of using them to train data scientists on good practices for robust solutions that can be productionized with little effort; increasing developer/data scientist velocity.&lt;/p&gt;
&lt;h3 id="Why-Git?"&gt;Why Git?&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/why-is-git-so-hard-to-understand/#Why-Git?"&gt;¬∂&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Git is the standard DVCS tool for groups of software professionals collaborating. To build robust projects that can be iterated and ideated on, git is the de-facto standard. It was initiated by &lt;a href="https://github.com/torvalds"&gt;Linus Torvalds&lt;/a&gt; which helped its adoption.&lt;/p&gt;
&lt;h3 id="What's-wrong-with-(G)it?"&gt;What's wrong with (G)it?&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/why-is-git-so-hard-to-understand/#What's-wrong-with-(G)it?"&gt;¬∂&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;With a little googling, I've found dozens of posts accepting that even seasoned developers can be puzzled by it's intricacies; git is widely recognized as difficult to use - &lt;a href="https://spderosso.github.io/onward13.pdf"&gt;[1]&lt;/a&gt;. Users find some working patterns and cling to them when developing - googling when things get out of hand, usually relying on &lt;code&gt;git reset --hard&lt;/code&gt; and &lt;code&gt;git reflog&lt;/code&gt; to get out of problems.&lt;/p&gt;
&lt;h3 id="No-Object-Model"&gt;No Object Model&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/why-is-git-so-hard-to-understand/#No-Object-Model"&gt;¬∂&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Git doesn't have a clean API with an object model. Git evolved somewhat organically as needs arose. Although some efforts were made to abstract out what was happening, it somehow got all mixed up.&lt;/p&gt;
&lt;h3 id="Plumbing,-Porcelain-and-Poop"&gt;Plumbing, Porcelain and Poop&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/why-is-git-so-hard-to-understand/#Plumbing,-Porcelain-and-Poop"&gt;¬∂&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;The original idea had been there would be low-level commands (for developers of git) were not for users, and instead they would use higher-level porcelain commands. Instead, as users became familiar and had various use cases, they dropped down into the low-level plumbing and the porcelain commands just didn't have enough expressive power. So now we have a poop-like (following plumbing and porcelain) situation where the ways to interact with git are so numerous and involved, that it's hard to keep a handle on.&lt;/p&gt;
&lt;h3 id="Data-Structures"&gt;Data Structures&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/why-is-git-so-hard-to-understand/#Data-Structures"&gt;¬∂&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Git makes use of, and inadvertently exposes several data structures - which are never thoroughly explained and often not needed for new users - adding to the mystique surrounding it.&lt;/p&gt;
&lt;h4 id="The-Git-Graph-Model"&gt;The Git Graph Model&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/why-is-git-so-hard-to-understand/#The-Git-Graph-Model"&gt;¬∂&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;The git graph model is a great way to understand how branches, commits and navigation work. However it relates to other concepts such as working tree, branch name pointers, HEAD and branch tips - all of which need time to be understood.&lt;/p&gt;
&lt;h4 id="Blobs"&gt;Blobs&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/why-is-git-so-hard-to-understand/#Blobs"&gt;¬∂&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;The Blobs are object stores that contain the contents of files. They are named using the contents of the file and a hashing algorithm.&lt;/p&gt;
&lt;h4 id="SHAs"&gt;SHAs&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/why-is-git-so-hard-to-understand/#SHAs"&gt;¬∂&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;The hashing algorithm is applied to git commits and blobs contents. It's not widely used by users.&lt;/p&gt;
&lt;h3 id="Naming-of-Commands"&gt;Naming of Commands&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/why-is-git-so-hard-to-understand/#Naming-of-Commands"&gt;¬∂&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;The naming of git commands is very different from other VCS systems and so can confuse users from other VCS systems.&lt;/p&gt;
&lt;h3 id="Distributed-Version-Control"&gt;Distributed Version Control&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/why-is-git-so-hard-to-understand/#Distributed-Version-Control"&gt;¬∂&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;The distributed in git's DVCS is the major innovation vs other VCS systems.&lt;/p&gt;
&lt;h3 id="Lack-of-Consistency-In-Command-Names"&gt;Lack of Consistency In Command Names&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/why-is-git-so-hard-to-understand/#Lack-of-Consistency-In-Command-Names"&gt;¬∂&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;The git commands have irregular names and flags, so that the same semantic operations have different names. This parable from &lt;a href="https://www.quora.com/Why-is-Git-so-hard-to-learn"&gt;quora&lt;/a&gt; is quite telling:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;A novice was learning at the feet of Master Git. At the end of the lesson he looked through his notes and said, ‚ÄúMaster, I have a few questions. May I ask them?‚Äù&lt;/p&gt;
&lt;p&gt;Master Git nodded.&lt;/p&gt;
&lt;p&gt;‚ÄúHow can I view a list of all tags?‚Äù&lt;/p&gt;
&lt;p&gt;‚Äúgit tag‚Äù, replied Master Git.&lt;/p&gt;
&lt;p&gt;‚ÄúHow can I view a list of all remotes?‚Äù&lt;/p&gt;
&lt;p&gt;‚Äúgit remote -v‚Äù, replied Master Git.&lt;/p&gt;
&lt;p&gt;‚ÄúHow can I view a list of all branches?‚Äù&lt;/p&gt;
&lt;p&gt;‚Äúgit branch -a‚Äù, replied Master Git.&lt;/p&gt;
&lt;p&gt;‚ÄúAnd how can I view the current branch?‚Äù&lt;/p&gt;
&lt;p&gt;‚Äúgit rev-parse --abbrev-ref HEAD‚Äù, replied Master Git.&lt;/p&gt;
&lt;p&gt;‚ÄúHow can I delete a remote?‚Äù&lt;/p&gt;
&lt;p&gt;‚Äúgit remote rm‚Äù, replied Master Git.&lt;/p&gt;
&lt;p&gt;‚ÄúAnd how can I delete a branch?‚Äù&lt;/p&gt;
&lt;p&gt;‚Äúgit branch -d‚Äù, replied Master Git.&lt;/p&gt;
&lt;p&gt;The novice thought for a few moments, then asked: ‚ÄúSurely some of these could be made more consistent, so as to be easier to remember in the heat of coding?‚Äù&lt;/p&gt;
&lt;p&gt;Master Git snapped his fingers. A hobgoblin entered the room and ate the novice alive. In the afterlife, the novice was enlightened.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="Conclusion"&gt;Conclusion&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/why-is-git-so-hard-to-understand/#Conclusion"&gt;¬∂&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Git is a genius piece of software. It is probably unnecessarily complicated and unwieldy, but given it's wide user base - we're stuck with it for some time to come. There are some efforts to produce a cleaner porcelain shell, such as &lt;a href="https://github.com/sdg-mit/gitless"&gt;gitless&lt;/a&gt; - they just haven't got enough traction for most organizations.&lt;/p&gt;
&lt;p&gt;Seems like it's ripe for disruption.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In¬†[¬†]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;&lt;/div&gt;</description><guid>https://project-delphi.github.io/blog/why-is-git-so-hard-to-understand/</guid><pubDate>Wed, 18 Sep 2019 23:56:10 GMT</pubDate></item><item><title>Directed Acyclic Graphs</title><link>https://project-delphi.github.io/blog/directed-acyclic-graphs/</link><dc:creator>Ravi Kalia</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Write your post here.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><guid>https://project-delphi.github.io/blog/directed-acyclic-graphs/</guid><pubDate>Wed, 18 Sep 2019 21:26:42 GMT</pubDate></item><item><title>Featureless Machine Learning: Classification</title><link>https://project-delphi.github.io/blog/featureless-machine-learning-classification/</link><dc:creator>Ravi Kalia</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Classification-Without-Features"&gt;Classification Without Features&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/featureless-machine-learning-classification/#Classification-Without-Features"&gt;¬∂&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Classification is applicable to new instances of categorical data - data that belongs to one of several types (or classes), the number of classes usually inferred from the data. This is discrete data. The major types of classes are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;binary (only two classes)&lt;/li&gt;
&lt;li&gt;multinomial (K classes with $K \geq 1$)&lt;/li&gt;
&lt;li&gt;ordinal (K classes with an ordering relation between them)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When there are no features, we can work with categorical data:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;describe the data with the distribution over the classes&lt;/li&gt;
&lt;li&gt;summarize the distribution with statistics&lt;/li&gt;
&lt;li&gt;instantiate classifiers that make use of the distribution&lt;/li&gt;
&lt;li&gt;generate sample variates from the distribution&lt;/li&gt;
&lt;li&gt;make use of bar charts, pie charts and tables to specify the distribution&lt;/li&gt;
&lt;li&gt;produce ROC, AUC metrics and their charts for featureless classifiers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If the data is a sample (usually the case), then the sample distribution is used as a proxy for the true distribution. The other useful strategy is use ensembling (such as bootstrap) to have a more robust (and less sticky to the data) estimate of the distribution.&lt;/p&gt;
&lt;p&gt;If the number of classes, K is very large (&amp;gt;15) - then interpreting charts becomes almost impossible - other than coarse proportions of the most frequent classes. The relativities don't come across well in charts or tables - so understanding is lost - unless the distribution is flat or dominated by a few classes; one might do well to aggregate the classes back up again.&lt;/p&gt;
&lt;p&gt;So let's roll these descriptions and predictions out using pandas, statsmodels, seaborn and sklearn.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In¬†[¬†]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;&lt;/div&gt;</description><guid>https://project-delphi.github.io/blog/featureless-machine-learning-classification/</guid><pubDate>Wed, 18 Sep 2019 00:28:45 GMT</pubDate></item><item><title>Intrusion Detection System</title><link>https://project-delphi.github.io/blog/intrusion-detection-system/</link><dc:creator>Ravi Kalia</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Write your post here.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><guid>https://project-delphi.github.io/blog/intrusion-detection-system/</guid><pubDate>Tue, 17 Sep 2019 02:59:26 GMT</pubDate></item><item><title>Causality Applications In 2019</title><link>https://project-delphi.github.io/blog/causality-applications-in-2019/</link><dc:creator>Ravi Kalia</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Causality:-Applications-in-2019"&gt;Causality: Applications in 2019&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/causality-applications-in-2019/#Causality:-Applications-in-2019"&gt;¬∂&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;It's now well established that there are &lt;a href="http://www.stat.cmu.edu/~ryantibs/journalclub/breiman_2001.pdf"&gt;two cultures in data modelling&lt;/a&gt;. These cultures are focused on one of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;prediction (discriminative modeling), or&lt;/li&gt;
&lt;li&gt;causality inferred from a data generating model (generative modeling)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Much of the machine learning community has used algorithmic solutions for prediction. Causality has not received as much attention in recent applications.&lt;/p&gt;
&lt;p&gt;There are three main academic disciplines addressing causality:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Computer Science&lt;/li&gt;
&lt;li&gt;Statistics&lt;/li&gt;
&lt;li&gt;Econometrics&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In another post we'll get into the details of these approaches (they all focus on how to block and account for confounders and aggregation strategies over the levels of blocked confounders).&lt;/p&gt;
&lt;p&gt;In an ideal world we would perform experiments and confidently find causal links between variables. However, most of the data being generated is observational which presents some challenges.&lt;/p&gt;
&lt;h3 id="AIOps"&gt;AIOps&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/causality-applications-in-2019/#AIOps"&gt;¬∂&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;In AIOps (using ML to aid solving Ops problems) some of the problems need prediction. However, given the cost of appliances and need for preemptive action before problems such as failure or delays occur, there is a need to identify which subset of features affect a target and how they do so.&lt;/p&gt;
&lt;h3 id="Growth-Hacking"&gt;Growth Hacking&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/causality-applications-in-2019/#Growth-Hacking"&gt;¬∂&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Growth Hacking is a set of principles to achieve fast sustainable growth using low cost alternatives to traditional marketing. Growth is usually defined as number of recurring users.&lt;/p&gt;
&lt;p&gt;The traditional measure of causality is to perform A/B testing controlling for confounding on features. Statistically if we measure number of users, we're looking at Poisson distribution or binomial estimate of changes in proportions. Alternatively, Poisson processes can be used to model the distribution.&lt;/p&gt;
&lt;p&gt;One rather important metric in growth hacking is the user retention rate. One way that this could be causally measured would be to leverage survival analysis methodology - again controlling for confounding.&lt;/p&gt;
&lt;p&gt;Of course in a fast growing business the features are usually confounding and changing rapidly. This presents a set of challenges which need to be carefully teased apart.&lt;/p&gt;
&lt;h3 id="Customer-Sentiment"&gt;Customer Sentiment&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/causality-applications-in-2019/#Customer-Sentiment"&gt;¬∂&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Finding the levers of customer or user sentiment is an open problem. That is identifying those features which&lt;/p&gt;
&lt;p&gt;A lot of these causal problems are related to data that is graphical (nodes and edges) by nature. It will be interesting to see how these develop.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><guid>https://project-delphi.github.io/blog/causality-applications-in-2019/</guid><pubDate>Mon, 16 Sep 2019 21:22:26 GMT</pubDate></item><item><title>Graphs, Graphs, Everywhere</title><link>https://project-delphi.github.io/blog/graphs-graphs-everywhere/</link><dc:creator>Ravi Kalia</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Graphs,-Graphs,-Everywhere"&gt;Graphs, Graphs, Everywhere&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/graphs-graphs-everywhere/#Graphs,-Graphs,-Everywhere"&gt;¬∂&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;I've revisited &lt;a href="https://en.wikipedia.org/wiki/Graph_theory"&gt;mathematical graphs&lt;/a&gt; (as opposed to &lt;a href="https://en.wikipedia.org/wiki/Chart"&gt;charts&lt;/a&gt;) in a number of settings in recent weeks. It's great to see graph theory at work in the world of 1's and 0's.&lt;/p&gt;
&lt;h3 id="Git"&gt;Git&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/graphs-graphs-everywhere/#Git"&gt;¬∂&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;I'm preparing a short course on git - and the most natural way to introduce the topic is with mathematical graphs. There's a lot to this perspective but broadly - commits are child nodes of earlier commits, going back to the root. Branches are just movable pointers to different commits.&lt;/p&gt;
&lt;h3 id="Machine-Learning-On-Graphs"&gt;Machine Learning On Graphs&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/graphs-graphs-everywhere/#Machine-Learning-On-Graphs"&gt;¬∂&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Arxiv papers are regularly raising the issue that many of the successful algorithms in Machine Learning depend on euclidean distance between points - &lt;a href="https://arxiv.org/pdf/1611.08097.pdf"&gt;[1]&lt;/a&gt;. However so much of our experiences and real world data records are not euclidean - in particular metric geometry seldom holds. There's been an explosion of research in applying graphs and manifolds as inputs and outputs to machine learning.&lt;/p&gt;
&lt;h4 id="Neural-Networks"&gt;Neural Networks&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/graphs-graphs-everywhere/#Neural-Networks"&gt;¬∂&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;Superficially choosing a neural network architecture is all about choosing a graph structure where inputs can flow to outputs over the edges, with many layers (Deep Learning) producing impressive results for a range of problems. Recurrent Neural Networks are also a type of graph, a linked list. Just worth noting the graphs, but tangential to non-euclidean learning.&lt;/p&gt;
&lt;p&gt;Convolutional neural networks - can be cast as local graph filters convolving to tensor data - particularly pixel data.&lt;/p&gt;
&lt;h4 id="Relationship-Networks"&gt;Relationship Networks&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/graphs-graphs-everywhere/#Relationship-Networks"&gt;¬∂&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;More interesting, relationship networks data is being generated all the time. People and businesses can be observed as nodes and the relationships, transactions between them as edges connecting nodes.&lt;/p&gt;
&lt;p&gt;There is active research on graphs with convolutional learning to learn graph structure with astounding results - &lt;a href="https://tkipf.github.io/graph-convolutional-networks/"&gt;[2]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Such networks are non-metric and more so, non-euclidean by nature; graphs are just a natural way to model them.&lt;/p&gt;
&lt;h4 id="Causality"&gt;Causality&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/graphs-graphs-everywhere/#Causality"&gt;¬∂&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;In trying to understand causality, assuming we have enough relevant covariates, then blocking confounders allows &lt;em&gt;ignorability&lt;/em&gt; to hold and then aggregation can be applied to estimate causal relationships.&lt;/p&gt;
&lt;p&gt;One popular way to do this is using Judea Pearl's do-calculus on DAGs of probability distributions and relationships between covariates and targets. Although somewhat unwieldy this is a promising area to model causality - along with variational Bayes methods. These DAG's are just graph structures where the relationships between variables are edges, and the variables themselves are node.&lt;/p&gt;
&lt;p&gt;Graphs seem to be occurring with increasing regularity. Their use to solve problems will be fascinating.&lt;/p&gt;
&lt;p&gt;Watch. This. Space.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In¬†[¬†]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;&lt;/div&gt;</description><guid>https://project-delphi.github.io/blog/graphs-graphs-everywhere/</guid><pubDate>Mon, 16 Sep 2019 21:17:40 GMT</pubDate></item></channel></rss>