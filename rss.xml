<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Ravi Kalia Blog</title><link>https://project-delphi.github.io/</link><description>Ravi Kalia's Blog</description><atom:link href="https://project-delphi.github.io/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2019 &lt;a href="mailto:ravkalia@gmail.com"&gt;Ravi Kalia&lt;/a&gt; </copyright><lastBuildDate>Wed, 18 Sep 2019 21:35:45 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Directed Acyclic Graphs</title><link>https://project-delphi.github.io/blog/directed-acyclic-graphs/</link><dc:creator>Ravi Kalia</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Write your post here.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><guid>https://project-delphi.github.io/blog/directed-acyclic-graphs/</guid><pubDate>Wed, 18 Sep 2019 21:26:42 GMT</pubDate></item><item><title>Featureless Machine Learning: Classification</title><link>https://project-delphi.github.io/blog/featureless-machine-learning-classification/</link><dc:creator>Ravi Kalia</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Write your post here.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><guid>https://project-delphi.github.io/blog/featureless-machine-learning-classification/</guid><pubDate>Wed, 18 Sep 2019 00:28:45 GMT</pubDate></item><item><title>Intrusion Detection System</title><link>https://project-delphi.github.io/blog/intrusion-detection-system/</link><dc:creator>Ravi Kalia</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Write your post here.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><guid>https://project-delphi.github.io/blog/intrusion-detection-system/</guid><pubDate>Tue, 17 Sep 2019 02:59:26 GMT</pubDate></item><item><title>Causality Applications In 2019</title><link>https://project-delphi.github.io/blog/causality-applications-in-2019/</link><dc:creator>Ravi Kalia</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Causality:-Applications-in-2019"&gt;Causality: Applications in 2019&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/causality-applications-in-2019/#Causality:-Applications-in-2019"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;It's now well established that there are &lt;a href="http://www.stat.cmu.edu/~ryantibs/journalclub/breiman_2001.pdf"&gt;two cultures in data modelling&lt;/a&gt;. These cultures are focused on one of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;prediction (discriminative modeling), or&lt;/li&gt;
&lt;li&gt;causality inferred from a data generating model (generative modeling)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Much of the machine learning community has used algorithmic solutions for prediction. Causality has not received as much attention in recent applications.&lt;/p&gt;
&lt;p&gt;There are three main academic disciplines addressing causality:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Computer Science&lt;/li&gt;
&lt;li&gt;Statistics&lt;/li&gt;
&lt;li&gt;Econometrics&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In another post we'll get into the details of these approaches (they all focus on how to block and account for confounders and aggregation strategies over the levels of blocked confounders).&lt;/p&gt;
&lt;p&gt;In an ideal world we would perform experiments and confidently find causal links between variables. However, most of the data being generated is observational which presents some challenges.&lt;/p&gt;
&lt;h3 id="AIOps"&gt;AIOps&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/causality-applications-in-2019/#AIOps"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;In AIOps (using ML to aid solving Ops problems) some of the problems need prediction. However, given the cost of appliances and need for preemptive action before problems such as failure or delays occur, there is a need to identify which subset of features affect a target and how they do so.&lt;/p&gt;
&lt;h3 id="Growth-Hacking"&gt;Growth Hacking&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/causality-applications-in-2019/#Growth-Hacking"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Growth Hacking is a set of principles to achieve fast sustainable growth using low cost alternatives to traditional marketing. Growth is usually defined as number of recurring users.&lt;/p&gt;
&lt;p&gt;The traditional measure of causality is to perform A/B testing controlling for confounding on features. Statistically if we measure number of users, we're looking at Poisson distribution or binomial estimate of changes in proportions. Alternatively, Poisson processes can be used to model the distribution.&lt;/p&gt;
&lt;p&gt;One rather important metric in growth hacking is the user retention rate. One way that this could be causally measured would be to leverage survival analysis methodology - again controlling for confounding.&lt;/p&gt;
&lt;p&gt;Of course in a fast growing business the features are usually confounding and changing rapidly. This presents a set of challenges which need to be carefully teased apart.&lt;/p&gt;
&lt;h3 id="Customer-Sentiment"&gt;Customer Sentiment&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/causality-applications-in-2019/#Customer-Sentiment"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Finding the levers of customer or user sentiment is an open problem. That is identifying those features which&lt;/p&gt;
&lt;p&gt;A lot of these causal problems are related to data that is graphical (nodes and edges) by nature. It will be interesting to see how these develop.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><guid>https://project-delphi.github.io/blog/causality-applications-in-2019/</guid><pubDate>Mon, 16 Sep 2019 21:22:26 GMT</pubDate></item><item><title>Graphs, Graphs, Everywhere</title><link>https://project-delphi.github.io/blog/graphs-graphs-everywhere/</link><dc:creator>Ravi Kalia</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Graphs,-Graphs,-Everywhere"&gt;Graphs, Graphs, Everywhere&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/graphs-graphs-everywhere/#Graphs,-Graphs,-Everywhere"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;I've revisited &lt;a href="https://en.wikipedia.org/wiki/Graph_theory"&gt;mathematical graphs&lt;/a&gt; (as opposed to &lt;a href="https://en.wikipedia.org/wiki/Chart"&gt;charts&lt;/a&gt;) in a number of settings in recent weeks. It's great to see graph theory at work in the world of 1's and 0's.&lt;/p&gt;
&lt;h3 id="Git"&gt;Git&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/graphs-graphs-everywhere/#Git"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;I'm preparing a short course on git - and the most natural way to introduce the topic is with mathematical graphs. There's a lot to this perspective but broadly - commits are child nodes of earlier commits, going back to the root. Branches are just movable pointers to different commits.&lt;/p&gt;
&lt;h3 id="Machine-Learning-On-Graphs"&gt;Machine Learning On Graphs&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/graphs-graphs-everywhere/#Machine-Learning-On-Graphs"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Arxiv papers are regularly raising the issue that many of the successful algorithms in Machine Learning depend on euclidean distance between points - &lt;a href="https://arxiv.org/pdf/1611.08097.pdf"&gt;[1]&lt;/a&gt;. However so much of our experiences and real world data records are not euclidean - in particular metric geometry seldom holds. There's been an explosion of research in applying graphs and manifolds as inputs and outputs to machine learning.&lt;/p&gt;
&lt;h4 id="Neural-Networks"&gt;Neural Networks&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/graphs-graphs-everywhere/#Neural-Networks"&gt;¶&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;Superficially choosing a neural network architecture is all about choosing a graph structure where inputs can flow to outputs over the edges, with many layers (Deep Learning) producing impressive results for a range of problems. Recurrent Neural Networks are also a type of graph, a linked list. Just worth noting the graphs, but tangential to non-euclidean learning.&lt;/p&gt;
&lt;p&gt;Convolutional neural networks - can be cast as local graph filters convolving to tensor data - particularly pixel data.&lt;/p&gt;
&lt;h4 id="Relationship-Networks"&gt;Relationship Networks&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/graphs-graphs-everywhere/#Relationship-Networks"&gt;¶&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;More interesting, relationship networks data is being generated all the time. People and businesses can be observed as nodes and the relationships, transactions between them as edges connecting nodes.&lt;/p&gt;
&lt;p&gt;There is active research on graphs with convolutional learning to learn graph structure with astounding results - &lt;a href="https://tkipf.github.io/graph-convolutional-networks/"&gt;[2]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Such networks are non-metric and more so, non-euclidean by nature; graphs are just a natural way to model them.&lt;/p&gt;
&lt;h4 id="Causality"&gt;Causality&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/graphs-graphs-everywhere/#Causality"&gt;¶&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;In trying to understand causality, assuming we have enough relevant covariates, then blocking confounders allows &lt;em&gt;ignorability&lt;/em&gt; to hold and then aggregation can be applied to estimate causal relationships.&lt;/p&gt;
&lt;p&gt;One popular way to do this is using Judea Pearl's do-calculus on DAGs of probability distributions and relationships between covariates and targets. Although somewhat unwieldy this is a promising area to model causality - along with variational Bayes methods. These DAG's are just graph structures where the relationships between variables are edges, and the variables themselves are node.&lt;/p&gt;
&lt;p&gt;Graphs seem to be occurring with increasing regularity. Their use to solve problems will be fascinating.&lt;/p&gt;
&lt;p&gt;Watch. This. Space.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [ ]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;&lt;/div&gt;</description><guid>https://project-delphi.github.io/blog/graphs-graphs-everywhere/</guid><pubDate>Mon, 16 Sep 2019 21:17:40 GMT</pubDate></item><item><title>Learning Git</title><link>https://project-delphi.github.io/blog/learning-git/</link><dc:creator>Ravi Kalia</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Learning-Git"&gt;Learning Git&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/learning-git/#Learning-Git"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;I was recently asked how I would introduce git to new data scientists.&lt;/p&gt;
&lt;p&gt;It's been so long since I was a noob to it, and really only picking up commands and understanding them as needed - that I decided to think it through from basics. Below are some broad steps, I'll try and write posts with links to resources on each of these.&lt;/p&gt;
&lt;p&gt;A key part of understanding Git is that there are multiple interpretations on what is happening when using git - &lt;a href="http://www2.math.uu.se/~thulin/mm/breiman.pdf"&gt;[1]&lt;/a&gt;, the so called Rashomon effect. Also bear in mind that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a repository is a container, a hidden folder and sometimes referred to as the commit tree&lt;/li&gt;
&lt;li&gt;there are many effective workflows for using git&lt;/li&gt;
&lt;li&gt;there are multiple ways to achieve a desired outcome&lt;/li&gt;
&lt;li&gt;several features of git that aren't explicitly related to one another&lt;/li&gt;
&lt;li&gt;only some features are needed for certain workflows&lt;/li&gt;
&lt;li&gt;some workflows rely on features (such as pull requests) that are not available in git, but through hosting services such as github and bitbucket&lt;/li&gt;
&lt;li&gt;the git API has ~200 commands that act on the git repository object, about 40 of those commands are needed for 99% of use cases.&lt;/li&gt;
&lt;li&gt;(~15 of those 40 commands have 4/5 regularly used flag options.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Perhaps the best description of git is "it's a type of version control system for a project with features that enable collaboration between individual contributors" - &lt;a href="https://www.atlassian.com/git"&gt;[2]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In the end, the best way to operate git is to just use it.&lt;/p&gt;
&lt;h3 id="A-Version-Control-System"&gt;A Version Control System&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/learning-git/#A-Version-Control-System"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;A version control system (VCS) on a project allows making checkpoints, recording the state of the project - files and sub-folders, as it evolves over time. These checkpoints are recorded to a store using the difference between the current state and the previous checkpoint. Any VCS has methods to navigate to different states of the checkpoints. When called to a certain checkpoint, these methods change the repository container (files and sub-folders) to the state of the checkpoint.&lt;/p&gt;
&lt;p&gt;Git is a type of VCS - it records checkpoints as commits and allows navigating them. These checkpoint commits point back to earlier commits, until the root commit, which is the first checkpoint. Therefore a sequence of commits forms a data structure that is a tree - a special kind of mathematical graph, often referred to as as the repository. Hence a commit has only one parent - another commit, unless a merge is being made.&lt;/p&gt;
&lt;p&gt;To make a checkpoint, the incantation is a two-step procedure. First, files are marked as in a staging area. Second, once there is a coherent small piece of work in the staging area, this unit of work is checkpointed as a commit to the repository. The idea is that staging allows forming commits as a set of changes to a number of specific files, as opposed to changes that may not be relevant. In practice, many find that staging is an extra step - all files modified/created since a commit are committed to the next commit.&lt;/p&gt;
&lt;p&gt;Nonetheless, in addition to navigating commits, some methods are needed to add, remove files to the staging area. In addition sometimes a block of changes can be stashed to a local store so that navigating commits can still be allowed.&lt;/p&gt;
&lt;h3 id="The-Repository-Is-a-Commit-Graph"&gt;The Repository Is a Commit Graph&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/learning-git/#The-Repository-Is-a-Commit-Graph"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;As mentioned, these commits form a graph in the repository. The commits are Nodes and they point to parent commits. Navigating to a commit changes the repository to the state of the previous commit.&lt;/p&gt;
&lt;h3 id="Branches:-Pointers-To-Nodes"&gt;Branches: Pointers To Nodes&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/learning-git/#Branches:-Pointers-To-Nodes"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;A branch is just a moveable pointer to a particular leaf tip Node on the commit tree. When on a branch, the HEAD (reference to a commit) is automatically changed if a new commit is made.&lt;/p&gt;
&lt;p&gt;A detached HEAD state is when a commit is navigated to without a branch. It is also possible to change the tip node of a branch by forcing a change.&lt;/p&gt;
&lt;h3 id="Combining-Branches"&gt;Combining Branches&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/learning-git/#Combining-Branches"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;img src="https://i.stack.imgur.com/nWYnQ.png" alt="Repo in Folder"&gt;&lt;/p&gt;
&lt;p&gt;To deeply understand combining branches, we need to understand the storage locations and data model of git. However, as a user - the API, given through commands, is often enough:&lt;/p&gt;
&lt;p&gt;There are three main ways to combine branches:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;merge &lt;/li&gt;
&lt;li&gt;rebase &lt;/li&gt;
&lt;li&gt;pull (which is a fetch followed by a merge for a remote branch)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="Fetch"&gt;Fetch&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/learning-git/#Fetch"&gt;¶&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;Remote repositories have local tracking branches when linked to a local repository. A fetch command updates the tracking branch to match the commits up to the tip of the remote repository's branch.&lt;/p&gt;
&lt;h4 id="Merge"&gt;Merge&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/learning-git/#Merge"&gt;¶&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;It is possible to create a new commit which combines two branches. Merges happen when a commit is added to a branch that incorporates the tip commit of another branch. If there are conflicts, the git user has to choose how to fix those.&lt;/p&gt;
&lt;p&gt;Once the merge is completed, the merge commit is the leaf tip on the branch being merged into. Depending on the workflow the branch that was merged from can be deleted.&lt;/p&gt;
&lt;h4 id="Pull"&gt;Pull&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/learning-git/#Pull"&gt;¶&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;A pull is a fetch from remote repository branch, followed by a merge. If the merge fails, then the user is prompted to resolve the conflict or abort.&lt;/p&gt;
&lt;h4 id="Rebase-And-Reset"&gt;Rebase And Reset&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/learning-git/#Rebase-And-Reset"&gt;¶&lt;/a&gt;&lt;/h4&gt;&lt;h3 id="Commonly-Used-Git-Commands"&gt;Commonly Used Git Commands&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/learning-git/#Commonly-Used-Git-Commands"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;h3 id="Remote-Repository"&gt;Remote Repository&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/learning-git/#Remote-Repository"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;h3 id="Remote-Branches"&gt;Remote Branches&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/learning-git/#Remote-Branches"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;h3 id="Collaborative-Git:-GitHub"&gt;Collaborative Git: GitHub&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/learning-git/#Collaborative-Git:-GitHub"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;h3 id="WorkFlows"&gt;WorkFlows&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/learning-git/#WorkFlows"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;h4 id="Centralized-Workflow"&gt;Centralized Workflow&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/learning-git/#Centralized-Workflow"&gt;¶&lt;/a&gt;&lt;/h4&gt;&lt;h4 id="Feature-Branch-Workflow"&gt;Feature Branch Workflow&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/learning-git/#Feature-Branch-Workflow"&gt;¶&lt;/a&gt;&lt;/h4&gt;&lt;h4 id="Forking-Workflow"&gt;Forking Workflow&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/learning-git/#Forking-Workflow"&gt;¶&lt;/a&gt;&lt;/h4&gt;&lt;h4 id="Git-Flow-Workflow"&gt;Git Flow Workflow&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/learning-git/#Git-Flow-Workflow"&gt;¶&lt;/a&gt;&lt;/h4&gt;&lt;h4 id="GitHub-Workflow"&gt;GitHub Workflow&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/learning-git/#GitHub-Workflow"&gt;¶&lt;/a&gt;&lt;/h4&gt;&lt;h4 id="GitLab-Workflow"&gt;GitLab Workflow&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/learning-git/#GitLab-Workflow"&gt;¶&lt;/a&gt;&lt;/h4&gt;&lt;h4 id="One-Workflow"&gt;One Workflow&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/learning-git/#One-Workflow"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [ ]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;&lt;/div&gt;</description><guid>https://project-delphi.github.io/blog/learning-git/</guid><pubDate>Mon, 16 Sep 2019 21:16:03 GMT</pubDate></item><item><title>AIOps vs MLOps</title><link>https://project-delphi.github.io/blog/aiops-vs-mlops/</link><dc:creator>Ravi Kalia</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="AIOps-vs-MLOps"&gt;AIOps vs MLOps&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/aiops-vs-mlops/#AIOps-vs-MLOps"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;I'm going to be speaking on MLOps soon. I also came across the term &lt;em&gt;AIOps&lt;/em&gt; in my preparation. Initially I had thought it was just a buzzy synonym for MLOps. However, after investigating some more, it seems at least some organizations differentiate between the two.&lt;/p&gt;
&lt;h3 id="MLOps"&gt;MLOps&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/aiops-vs-mlops/#MLOps"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;MLOps is the process of taking a ML solution and bringing it to production. It needs a culture and tools that connect concerns in ML systems development with concerns in ML systems operations - &lt;a href="https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf"&gt;[1]&lt;/a&gt;. This touches on a number of themes such as CI/CD, data reliability, monitoring, scaling, decoupling, and fast deployment to production, avoiding fragile systems.&lt;/p&gt;
&lt;h3 id="AIOps"&gt;AIOps&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/aiops-vs-mlops/#AIOps"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Ops, or Operations - already went through a revolution known as DevOps - where changes and deployment became something that an application developer can do by using cloud services and orchestration software.&lt;/p&gt;
&lt;p&gt;AIOps is about bringing machine learning techniques to solve Ops problems such as reliability, monitoring, capacity management, service desks and even more automation than natively available through DevOps - &lt;a href="https://www.lakesidesoftware.com/blog/guide-aiops-tools-2019-how-choose-key-concepts"&gt;[2]&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="Causality"&gt;Causality&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/aiops-vs-mlops/#Causality"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;One interesting aspect of AIOps is that causality is very important to many of the problems in the space. That is knowing the cause of problems and possible solutions is as important as predicting problems such as failure.&lt;/p&gt;
&lt;p&gt;In many traditionally ML algorithms, causality is not the focus and it is left to the realm of statistics to identify which features cause changes in the target - &lt;a href="http://w3.mi.parisdescartes.fr/~chambaz/Atelier209/07vanderLaan.pdf"&gt;[3]&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [ ]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;&lt;/div&gt;</description><guid>https://project-delphi.github.io/blog/aiops-vs-mlops/</guid><pubDate>Mon, 16 Sep 2019 19:53:44 GMT</pubDate></item><item><title>Featureless Machine Learning</title><link>https://project-delphi.github.io/blog/featureless-machine-learning/</link><dc:creator>Ravi Kalia</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Featureless-Machine-Learning"&gt;Featureless Machine Learning&lt;a class="anchor-link" href="https://project-delphi.github.io/blog/featureless-machine-learning/#Featureless-Machine-Learning"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Often it helps to refresh grounding in the fundamentals. I'm writing a sequence of posts to touch base with some machine learning/stats techniques - but without features.&lt;/p&gt;
&lt;p&gt;Without features, we are forced to focus on the learning task with just univariate data. This give context to charts and often flattens the cute maths that we can spend too much time on.&lt;/p&gt;
&lt;p&gt;In the major cultural split of prediction and causation - there really isn't much causation without features - that's the whole point of causation to link some subset of features to an outcome or target - &lt;a href="https://arxiv.org/pdf/1101.0891.pdf"&gt;[1]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;One other reason to do this, is that when features are held constant at some level - say for some kind of causality analysis - we can still look at the univariate variable of interest.&lt;/p&gt;
&lt;p&gt;Let's break our foray into featureless machine learning using the standard groupings for ML algorithms. That is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Supervised Learning&lt;ul&gt;
&lt;li&gt;Classification&lt;/li&gt;
&lt;li&gt;Regression&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Unsupervised Learning &lt;ul&gt;
&lt;li&gt;Data Reduction&lt;/li&gt;
&lt;li&gt;Clustering&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When there are no features, these groupings are referenced by other names - such as density estimation or mixture of distributions. We'll break these into separate posts focused on each group of problems.&lt;/p&gt;
&lt;p&gt;(We won't dwell on reinforcement learning, since I don't have enough exposure to the area to discuss it.)&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [ ]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;&lt;/div&gt;</description><guid>https://project-delphi.github.io/blog/featureless-machine-learning/</guid><pubDate>Mon, 16 Sep 2019 18:38:54 GMT</pubDate></item></channel></rss>